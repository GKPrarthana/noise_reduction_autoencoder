{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5716da36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Prarthana\\\\Desktop\\\\projects\\\\noise_reduction_autoencoder\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99942d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Prarthana\\\\Desktop\\\\projects\\\\noise_reduction_autoencoder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200de78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List    \n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class DataSplittingConfig:\n",
    "    root_dir: Path\n",
    "    train_clean_dir: Path\n",
    "    train_noisy_dir: Path\n",
    "    val_clean_dir: Path\n",
    "    val_noisy_dir: Path\n",
    "    test_clean_dir: Path\n",
    "    test_noisy_dir: Path\n",
    "    split_ratios: List[float]\n",
    "    clean_data_source: Path\n",
    "    noisy_data_source: Path\n",
    "    params: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b3f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update config manager\n",
    "from src.constants import *\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "#from src.entity.config_entity import DataSplittingConfig\n",
    "\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([Path(self.config.artifacts_root)])\n",
    "\n",
    "\n",
    "    def get_data_splitting_config(self) -> DataSplittingConfig:\n",
    "        config = self.config.data_splitting\n",
    "        create_directories([\n",
    "            Path(config.root_dir), Path(config.train_clean_dir), Path(config.train_noisy_dir),\n",
    "            Path(config.val_clean_dir), Path(config.val_noisy_dir),\n",
    "            Path(config.test_clean_dir), Path(config.test_noisy_dir)\n",
    "        ])\n",
    "        return DataSplittingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            train_clean_dir=Path(config.train_clean_dir),\n",
    "            train_noisy_dir=Path(config.train_noisy_dir),\n",
    "            val_clean_dir=Path(config.val_clean_dir),\n",
    "            val_noisy_dir=Path(config.val_noisy_dir),\n",
    "            test_clean_dir=Path(config.test_clean_dir),\n",
    "            test_noisy_dir=Path(config.test_noisy_dir),\n",
    "            split_ratios=config.split_ratios,\n",
    "            clean_data_source=Path(config.clean_data_source),\n",
    "            noisy_data_source=Path(config.noisy_data_source),\n",
    "            params=self.params\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad6289d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from src import logger\n",
    "from src.utils.common import create_directories\n",
    "#from src.entity.config_entity import DataSplittingConfig\n",
    "\n",
    "class DataSplitting:\n",
    "    def __init__(self, config: DataSplittingConfig):\n",
    "        \"\"\"Initialize with configuration.\"\"\"\n",
    "        self.config = config\n",
    "        create_directories([\n",
    "            self.config.train_clean_dir, self.config.train_noisy_dir,\n",
    "            self.config.val_clean_dir, self.config.val_noisy_dir,\n",
    "            self.config.test_clean_dir, self.config.test_noisy_dir\n",
    "        ])\n",
    "\n",
    "    def split_dataset(self):\n",
    "        \"\"\"Split clean and noisy images into train, validation, and test sets.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting data splitting\")\n",
    "            clean_base_dir = Path(self.config.clean_data_source)  # artifacts/data_ingestion/pneumonia_xray\n",
    "            noisy_base_dir = Path(self.config.noisy_data_source)  # artifacts/data_ingestion/noisy_images\n",
    "            train_ratio, val_ratio, test_ratio = self.config.split_ratios\n",
    "\n",
    "            for label in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "                # Collect all clean images directly from pneumonia_xray/NORMAL or PNEUMONIA\n",
    "                label_clean_dir = clean_base_dir / label\n",
    "                if not label_clean_dir.exists():\n",
    "                    logger.warning(f\"Directory {label_clean_dir} not found\")\n",
    "                    continue\n",
    "                clean_images = list(label_clean_dir.glob(\"*.jpeg\"))\n",
    "                \n",
    "                if not clean_images:\n",
    "                    logger.warning(f\"No clean images found for {label} in {clean_base_dir}\")\n",
    "                    continue\n",
    "\n",
    "                # Map clean images to noisy images\n",
    "                noisy_images = []\n",
    "                for clean_img in clean_images:\n",
    "                    noisy_img_path = noisy_base_dir / label / clean_img.name\n",
    "                    if not noisy_img_path.exists():\n",
    "                        logger.warning(f\"Noisy image {noisy_img_path} not found for {clean_img}\")\n",
    "                        continue\n",
    "                    noisy_images.append(noisy_img_path)\n",
    "\n",
    "                # Ensure we have matching pairs\n",
    "                if len(clean_images) != len(noisy_images):\n",
    "                    logger.warning(f\"Mismatch: {len(clean_images)} clean images vs {len(noisy_images)} noisy images for {label}\")\n",
    "                    continue\n",
    "\n",
    "                # Split images\n",
    "                train_clean, temp_clean = train_test_split(clean_images, train_size=train_ratio, random_state=42)\n",
    "                val_clean, test_clean = train_test_split(temp_clean, train_size=val_ratio/(val_ratio + test_ratio), random_state=42)\n",
    "\n",
    "                # Split noisy images using the same indices\n",
    "                train_indices = [clean_images.index(img) for img in train_clean]\n",
    "                val_indices = [clean_images.index(img) for img in val_clean]\n",
    "                test_indices = [clean_images.index(img) for img in test_clean]\n",
    "                train_noisy = [noisy_images[i] for i in train_indices]\n",
    "                val_noisy = [noisy_images[i] for i in val_indices]\n",
    "                test_noisy = [noisy_images[i] for i in test_indices]\n",
    "\n",
    "                # Copy images to respective directories\n",
    "                for split, clean_imgs, noisy_imgs, clean_dir, noisy_dir in [\n",
    "                    (\"train\", train_clean, train_noisy, self.config.train_clean_dir / label, self.config.train_noisy_dir / label),\n",
    "                    (\"val\", val_clean, val_noisy, self.config.val_clean_dir / label, self.config.val_noisy_dir / label),\n",
    "                    (\"test\", test_clean, test_noisy, self.config.test_clean_dir / label, self.config.test_noisy_dir / label)\n",
    "                ]:\n",
    "                    create_directories([clean_dir, noisy_dir])\n",
    "                    for clean_img, noisy_img in zip(clean_imgs, noisy_imgs):\n",
    "                        shutil.copy(clean_img, clean_dir / clean_img.name)\n",
    "                        shutil.copy(noisy_img, noisy_dir / noisy_img.name)\n",
    "                    logger.info(f\"Copied {len(clean_imgs)} images to {split} for {label}\")\n",
    "            logger.info(\"Data splitting completed\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data splitting failed: {e}\", exc_info=True)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29b7aa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts\\data_ingestion\\pneumonia_xray\\NORMAL: 234 images\n",
      "artifacts\\data_ingestion\\pneumonia_xray\\PNEUMONIA: 390 images\n",
      "artifacts\\data_ingestion\\noisy_images\\NORMAL: 234 images\n",
      "artifacts\\data_ingestion\\noisy_images\\PNEUMONIA: 390 images\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Verify clean images\n",
    "clean_base_path = \"artifacts/data_ingestion/pneumonia_xray\"\n",
    "for label in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "    dir_path = Path(clean_base_path) / label\n",
    "    count = len(list(dir_path.glob(\"*.jpeg\")))\n",
    "    print(f\"{dir_path}: {count} images\")\n",
    "\n",
    "# Verify noisy images\n",
    "noisy_base_path = \"artifacts/data_ingestion/noisy_images\"\n",
    "for label in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "    dir_path = Path(noisy_base_path) / label\n",
    "    count = len(list(dir_path.glob(\"*.jpeg\")))\n",
    "    print(f\"{dir_path}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f13d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\Prarthana\\Desktop\\projects\\noise_reduction_autoencoder\n",
      "[2025-04-23 21:41:39,128: INFO: common: YAML file: c:\\Users\\Prarthana\\Desktop\\projects\\noise_reduction_autoencoder\\config\\config.yaml loaded successfully]\n",
      "[2025-04-23 21:41:39,147: INFO: common: YAML file: c:\\Users\\Prarthana\\Desktop\\projects\\noise_reduction_autoencoder\\params.yaml loaded successfully]\n",
      "[2025-04-23 21:41:39,158: INFO: common: Created directory at: artifacts]\n",
      "[2025-04-23 21:41:39,161: INFO: common: Created directory at: artifacts\\data]\n",
      "[2025-04-23 21:41:39,169: INFO: common: Created directory at: artifacts\\data\\train\\clean]\n",
      "[2025-04-23 21:41:39,176: INFO: common: Created directory at: artifacts\\data\\train\\noisy]\n",
      "[2025-04-23 21:41:39,185: INFO: common: Created directory at: artifacts\\data\\val\\clean]\n",
      "[2025-04-23 21:41:39,189: INFO: common: Created directory at: artifacts\\data\\val\\noisy]\n",
      "[2025-04-23 21:41:39,191: INFO: common: Created directory at: artifacts\\data\\test\\clean]\n",
      "[2025-04-23 21:41:39,194: INFO: common: Created directory at: artifacts\\data\\test\\noisy]\n",
      "[2025-04-23 21:41:39,199: INFO: common: Created directory at: artifacts\\data\\train\\clean]\n",
      "[2025-04-23 21:41:39,205: INFO: common: Created directory at: artifacts\\data\\train\\noisy]\n",
      "[2025-04-23 21:41:39,210: INFO: common: Created directory at: artifacts\\data\\val\\clean]\n",
      "[2025-04-23 21:41:39,214: INFO: common: Created directory at: artifacts\\data\\val\\noisy]\n",
      "[2025-04-23 21:41:39,220: INFO: common: Created directory at: artifacts\\data\\test\\clean]\n",
      "[2025-04-23 21:41:39,225: INFO: common: Created directory at: artifacts\\data\\test\\noisy]\n",
      "[2025-04-23 21:41:39,228: INFO: 1196720098: Starting data splitting]\n",
      "[2025-04-23 21:41:39,335: INFO: common: Created directory at: artifacts\\data\\train\\clean\\NORMAL]\n",
      "[2025-04-23 21:41:39,337: INFO: common: Created directory at: artifacts\\data\\train\\noisy\\NORMAL]\n",
      "[2025-04-23 21:41:44,424: INFO: 1196720098: Copied 163 images to train for NORMAL]\n",
      "[2025-04-23 21:41:44,431: INFO: common: Created directory at: artifacts\\data\\val\\clean\\NORMAL]\n",
      "[2025-04-23 21:41:44,437: INFO: common: Created directory at: artifacts\\data\\val\\noisy\\NORMAL]\n",
      "[2025-04-23 21:41:45,585: INFO: 1196720098: Copied 35 images to val for NORMAL]\n",
      "[2025-04-23 21:41:45,589: INFO: common: Created directory at: artifacts\\data\\test\\clean\\NORMAL]\n",
      "[2025-04-23 21:41:45,591: INFO: common: Created directory at: artifacts\\data\\test\\noisy\\NORMAL]\n",
      "[2025-04-23 21:41:46,503: INFO: 1196720098: Copied 36 images to test for NORMAL]\n",
      "[2025-04-23 21:41:46,655: INFO: common: Created directory at: artifacts\\data\\train\\clean\\PNEUMONIA]\n",
      "[2025-04-23 21:41:46,658: INFO: common: Created directory at: artifacts\\data\\train\\noisy\\PNEUMONIA]\n",
      "[2025-04-23 21:41:52,768: INFO: 1196720098: Copied 273 images to train for PNEUMONIA]\n",
      "[2025-04-23 21:41:52,771: INFO: common: Created directory at: artifacts\\data\\val\\clean\\PNEUMONIA]\n",
      "[2025-04-23 21:41:52,773: INFO: common: Created directory at: artifacts\\data\\val\\noisy\\PNEUMONIA]\n",
      "[2025-04-23 21:41:53,764: INFO: 1196720098: Copied 58 images to val for PNEUMONIA]\n",
      "[2025-04-23 21:41:53,767: INFO: common: Created directory at: artifacts\\data\\test\\clean\\PNEUMONIA]\n",
      "[2025-04-23 21:41:53,769: INFO: common: Created directory at: artifacts\\data\\test\\noisy\\PNEUMONIA]\n",
      "[2025-04-23 21:41:56,014: INFO: 1196720098: Copied 59 images to test for PNEUMONIA]\n",
      "[2025-04-23 21:41:56,018: INFO: 1196720098: Data splitting completed]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "#from src import logger, ConfigurationManager, DataSplitting\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_splitting_config = config.get_data_splitting_config()\n",
    "    data_splitting = DataSplitting(config=data_splitting_config)\n",
    "    data_splitting.split_dataset()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in data splitting: {e}\", exc_info=True)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec9a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denoise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
